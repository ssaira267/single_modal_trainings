{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086a57eb",
   "metadata": {},
   "source": [
    "# VGG19 Transfer Learning on FMS Images for Carbonate Rock Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd25612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bca3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_generators(train_dir, val_dir, test_dir, image_size, batch_size):\n",
    "    \"\"\" Create image data generators for training, validation, and testing. \"\"\"\n",
    "    datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        train_dir, target_size=image_size, class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        val_dir, target_size=image_size, class_mode='categorical', batch_size=batch_size, shuffle=False, seed=42)\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        test_dir, target_size=image_size, class_mode=None, batch_size=1, shuffle=False, seed=42)\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\" Build and compile a VGG19 model for image classification. \"\"\"\n",
    "    conv_base = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_gen, val_gen, n_steps, n_val_steps, n_epochs, weights_path, plot_losses=True):\n",
    "    \"\"\" Train and evaluate the model, save best weights, and plot training progress. \"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=weights_path, save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, mode='min')\n",
    "    ]\n",
    "    if plot_losses:\n",
    "        from livelossplot.inputs.keras import PlotLossesCallback\n",
    "        callbacks.append(PlotLossesCallback())\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen, epochs=n_epochs, validation_data=val_gen,\n",
    "        steps_per_epoch=n_steps, validation_steps=n_val_steps,\n",
    "        callbacks=callbacks, verbose=1\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, test_gen, true_classes):\n",
    "    \"\"\" Evaluate the model's accuracy and display confusion matrix. \"\"\"\n",
    "    preds = model.predict(test_gen)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    accuracy = accuracy_score(true_classes, pred_classes)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "def plot_confusion_matrix(true_classes, pred_classes, class_names):\n",
    "    \"\"\" Plot confusion matrix for model predictions. \"\"\"\n",
    "    cm = confusion_matrix(true_classes, pred_classes)\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_dir, n_classes, batch_size, image_size=(224, 224), n_epochs=200, learning_rate=0.001, fine_tune=0):\n",
    "    \"\"\" Main function to set up and run the training process. \"\"\"\n",
    "    train_dir = data_dir/'train'\n",
    "    val_dir = data_dir/'val'\n",
    "    test_dir = data_dir/'test'\n",
    "    \n",
    "    train_gen, val_gen, test_gen = create_image_generators(train_dir, val_dir, test_dir, image_size, batch_size)\n",
    "    model = create_model(image_size + (3,), n_classes, Adam(learning_rate=learning_rate), fine_tune)\n",
    "    \n",
    "    weights_path = f\"{data_dir}/model_best.weights.hdf5\"\n",
    "    train_model(model, train_gen, val_gen, len(train_gen), len(val_gen), n_epochs, weights_path)\n",
    "    \n",
    "    true_classes = test_gen.classes\n",
    "    evaluate_model(model, test_gen, true_classes)\n",
    "    preds = model.predict(test_gen)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    plot_confusion_matrix(true_classes, pred_classes, list(test_gen.class_indices.keys()))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = Path(\"/path/to/your/data\")\n",
    "    main(data_dir, n_classes=5, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
